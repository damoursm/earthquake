{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install a few libraries"
      ],
      "metadata": {
        "id": "AlaWGXf1UZ03"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PhXmiTsh8DX",
        "outputId": "be3a39cc-2bc5-485e-9bab-8852b679e2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "! pip install torch torchvision matplotlib numpy scikit-image torchinfo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "tpW38QCHi5XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io as io\n",
        "from pathlib import Path\n",
        "import sys"
      ],
      "metadata": {
        "id": "wtQZlF9Ri7Lu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility functions"
      ],
      "metadata": {
        "id": "908G44i-jFAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the time-series of errors and accuracies\n",
        "# for validation and train splits\n",
        "def plot_error_and_accuracy(errors, accuracies, title=\"\"):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        errors (dict): dictionary of errors over epochs {\"train\": [], \"val\": []}\n",
        "        accuracies (dict): similar, for accuracy\n",
        "        title (optional, str): Plot title. Defaults to \"\".\n",
        "    \"\"\"\n",
        "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    x = range(len(errors[\"train\"]))\n",
        "    ax1.plot(x, errors[\"train\"], label=\"Training\")\n",
        "    ax1.plot(x, errors[\"val\"], label=\"Validation\")\n",
        "    ax1.title.set_text(\"Cross-entropy error\")\n",
        "\n",
        "    ax2.plot(x, accuracies[\"train\"], label=\"Training\")\n",
        "    ax2.plot(x, accuracies[\"val\"], label=\"Validation\")\n",
        "    ax2.title.set_text(\"Prediction Accuracy\")\n",
        "\n",
        "    if title:\n",
        "        plt.suptitle(title)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oJdHS6dwjGs1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPUMonitor class to monitor GPU utilization in the background\n",
        "\n",
        "import subprocess\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "def gpu_util():\n",
        "    format = \"csv,nounits,noheader\"\n",
        "    queries = [\"utilization.gpu\", \"memory.used\", \"memory.free\", \"utilization.memory\"]\n",
        "    gpu_query = \",\".join(queries)\n",
        "    gpu_ids = 0\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [\n",
        "            shutil.which(\"nvidia-smi\"),\n",
        "            f\"--query-gpu={gpu_query}\",\n",
        "            f\"--format={format}\",\n",
        "            f\"--id={gpu_ids}\",\n",
        "        ],\n",
        "        encoding=\"utf-8\",\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        check=True,\n",
        "    )\n",
        "    stats = [\n",
        "        [float(x) for x in s.split(\", \")]\n",
        "        for s in result.stdout.strip().split(os.linesep)\n",
        "    ][0]\n",
        "    utilization = {}\n",
        "    for k, q in enumerate(queries):\n",
        "        utilization[q] = stats[k]\n",
        "    return utilization\n",
        "\n",
        "\n",
        "from threading import Thread\n",
        "from time import sleep, time\n",
        "\n",
        "\n",
        "class GPUMonitor:\n",
        "    def __init__(self, timeout=1):\n",
        "        self.timeout = timeout\n",
        "\n",
        "        self._thread = Thread(target=self._monitor, daemon=True)\n",
        "        self.utilization = None\n",
        "        self.done = False\n",
        "        self.start_time = self.stop_time = None\n",
        "\n",
        "    def start(self):\n",
        "        self._thread.start()\n",
        "        self.start_time = time()\n",
        "        return self\n",
        "\n",
        "    def _monitor(self):\n",
        "        while True:\n",
        "            if self.done:\n",
        "                break\n",
        "            utilization = gpu_util()\n",
        "            if self.utilization is None:\n",
        "                self.utilization = {k: [] for k in utilization}\n",
        "            for k, v in utilization.items():\n",
        "                self.utilization[k].append(v)\n",
        "            sleep(self.timeout)\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start()\n",
        "\n",
        "    def stop(self):\n",
        "        self.stop_time = time()\n",
        "        self.done = True\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, tb):\n",
        "        # handle exceptions with those variables ^\n",
        "        self.stop()\n",
        "\n",
        "    def plot_all(self, figsize=(10, 10)):\n",
        "        f, axs = plt.subplots(2, 2, figsize=figsize)\n",
        "        for i in range(2):\n",
        "            for j in range(2):\n",
        "                ax = axs[i][j]\n",
        "                k = list(self.utilization.keys())[i * 2 + j]\n",
        "                data = self.utilization[k]\n",
        "                ax.plot(range(len(data)), data)\n",
        "                ax.title.set_text(k)\n",
        "        plt.suptitle(\"GPU monitoring\")\n",
        "\n",
        "    def plot(self, k):\n",
        "        assert k in self.utilization, f\"Unknown metric {k}\"\n",
        "        data = self.utilization[k]\n",
        "        plt.plot(range(len(data)), data)\n",
        "        plt.title(\"GPU monitoring: \" + k)"
      ],
      "metadata": {
        "id": "llgRGPwojKdw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(predictions, labels):\n",
        "    \"\"\"\n",
        "    Counts the number of correct predictions\n",
        "\n",
        "    Args:\n",
        "        predictions (torch.Tensor): array of model predictions. Can be either\n",
        "            1D (batch of class indices) or 2D (batch of prediction vectors)\n",
        "        labels (torch.Tensor): array of ground truth target labels (1D)\n",
        "    \"\"\"\n",
        "    if predictions.ndim > labels.ndim:\n",
        "        predictions = predictions.max(1).indices\n",
        "\n",
        "    correct_predictions = predictions.cpu() == labels.cpu()\n",
        "    correct_count = correct_predictions.float().sum()\n",
        "    return correct_count.item()"
      ],
      "metadata": {
        "id": "NBZkVWZ9jioY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From\n",
        "# https://discuss.pytorch.org/t/reproducibility-with-all-the-bells-and-whistles/81097\n",
        "\n",
        "\n",
        "def seed_all(seed):\n",
        "    \"\"\"\n",
        "    Seed Python, Numpy and Pytorch for reproducibility.\n",
        "    \"\"\"\n",
        "\n",
        "    if not seed:\n",
        "        seed = 10\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # np.random.seed(seed)\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    return rng\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    \"\"\"\n",
        "    Seed data loader workers\n",
        "    \"\"\"\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "rng = seed_all(123)"
      ],
      "metadata": {
        "id": "1fMz9UxAlKnn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set training set and validation set.\n"
      ],
      "metadata": {
        "id": "zSFTZzkzVdBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_set = ...\n",
        "# val_set = ..."
      ],
      "metadata": {
        "id": "SQNrQ8WrVajS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create models"
      ],
      "metadata": {
        "id": "DjKDKfX9dOK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "dh7bB31gdeVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full training procedure"
      ],
      "metadata": {
        "id": "ZD05-o9wy2xX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameters\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "lr = 0.01\n",
        "\n",
        "# create device based on GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# create model <-------------------------------------------------------------\n",
        "# model = CNN().to(device)\n",
        "\n",
        "# as before: create optimizer and loss <-------------------------------------\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# store train/val error & accuracy\n",
        "errors = {\n",
        "    \"train\": [],\n",
        "    \"val\": [],\n",
        "}\n",
        "\n",
        "accuracies = {\"train\": [], \"val\": []}\n",
        "\n",
        "# initialize loaders\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True, num_workers=4\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, shuffle=False, num_workers=4\n",
        ")\n",
        "\n",
        "print(model)\n",
        "\n",
        "# custom object in order to monitor how much we use the GPU\n",
        "# you can have a look at it in 0. Imports and Utils\n",
        "monitor = GPUMonitor()\n",
        "monitor.start()\n",
        "\n",
        "# ---------------------------------------\n",
        "# --  Start of the training procedure  --\n",
        "# ---------------------------------------\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    train_errors = []\n",
        "    train_correct = 0\n",
        "\n",
        "    # Dropout and BatchNorm behave differently if you are training or evaluating\n",
        "    # the model. Here we need them to be in training mode\n",
        "    # (for instance, no dropout in evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    # ignore: clear print line\n",
        "    print(\" \" * 100, end=\"\")\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        print(f\"\\rEpoch {e+1}/{epochs} | Train Batch {i+1}/{len(train_loader)}\", end=\"\")\n",
        "\n",
        "        # clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # send tensors to the propper device\n",
        "        x = batch[\"input\"].to(device)\n",
        "        y = batch[\"label\"].to(device)\n",
        "\n",
        "        # forward through model\n",
        "        prediction = model(x)\n",
        "        # compute prediction error\n",
        "        error = loss(prediction, y)\n",
        "        # update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # store batch error\n",
        "        train_errors.append(error.cpu().item())\n",
        "        # store batch correct count (see 0. ) to compute accuracy\n",
        "        # on the full training set for this epoch\n",
        "        train_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "    # clear print line\n",
        "    print(\" \" * 100, end=\"\")\n",
        "\n",
        "    # evaluation: no gradients needed\n",
        "    with torch.no_grad():\n",
        "        val_errors = []\n",
        "        val_correct = 0\n",
        "\n",
        "        # Put the model in evaluation mode (vs .train() mode)\n",
        "        model.eval()\n",
        "\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            print(\n",
        "                f\"\\rEpoch {e+1}/{epochs} | Validation Batch {i+1}/{len(val_loader)}\",\n",
        "                end=\"\",\n",
        "            )\n",
        "            prediction = model(batch[\"input\"].to(device))\n",
        "            error = loss(prediction, batch[\"label\"].to(device))\n",
        "            val_errors.append(error.cpu().item())\n",
        "            val_correct += correct(prediction, batch[\"label\"])\n",
        "\n",
        "    # compute average errors\n",
        "    train_error = np.mean(train_errors)\n",
        "    val_error = np.mean(val_errors)\n",
        "\n",
        "    # compute epoch-wise accuracies\n",
        "    train_acc = train_correct / len(train_set) * 100\n",
        "    val_acc = val_correct / len(val_set) * 100\n",
        "\n",
        "    # store metrics\n",
        "    accuracies[\"train\"].append(train_acc)\n",
        "    accuracies[\"val\"].append(val_acc)\n",
        "    errors[\"train\"].append(train_error)\n",
        "    errors[\"val\"].append(val_error)\n",
        "\n",
        "    print(\n",
        "        f\"\\rEpoch {e+1}/{epochs} - Train error: {train_error:.4f} Train acc: {train_acc:.1f}% - Val error: {val_error:.4f} Val acc: {val_acc:.1f}%\"\n",
        "    )\n",
        "\n",
        "    # -------------------\n",
        "    # --  End of epoch --\n",
        "    # -------------------\n",
        "\n",
        "# -------------------------------------\n",
        "# --  End of the training procedure  --\n",
        "# -------------------------------------\n",
        "\n",
        "# stop the GPU monitor\n",
        "monitor.stop()"
      ],
      "metadata": {
        "id": "sLAYBQshlMen",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "17218840-8e92-4279-fbeb-0e174947ee53"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-368020e15d01>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# custom object in order to monitor how much we use the GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train and val losses as functions of epoch number\n",
        "plt.figure()\n",
        "plt.plot(errors[\"train\"], label=\"train\")\n",
        "plt.plot(errors[\"val\"], label=\"val\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.yscale(\"log\")"
      ],
      "metadata": {
        "id": "_Bc-nBX8zNGN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "85d8ea90-50c0-45c3-b21f-48505bc36d7d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}