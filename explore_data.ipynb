{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9638787b-eb90-44d3-8c50-1427bd34f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils.dataloaders.InstanceDataset import InstanceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6916fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_hdf5_file = \"data/instance_samples/Instance_events_counts_10k.hdf5\"\n",
    "event_metadata_file = \"data/instance_samples/metadata_Instance_events_10k.csv\"\n",
    "noise_hdf5_file = \"data/instance_samples/Instance_noise_1k.hdf5\"\n",
    "noise_metadata_file = \"data/instance_samples/metadata_Instance_noise_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c04581c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_P_arrival_time</th>\n",
       "      <th>trace_S_arrival_time</th>\n",
       "      <th>trace_P_arrival_sample</th>\n",
       "      <th>trace_S_arrival_sample</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>trace_GPD_P_number</th>\n",
       "      <th>trace_GPD_S_number</th>\n",
       "      <th>trace_EQT_number_detections</th>\n",
       "      <th>trace_EQT_P_number</th>\n",
       "      <th>trace_EQT_S_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-04T15:34:43.92Z</td>\n",
       "      <td>2016-12-04T15:35:01.27Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.OFFI..HH</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-04T15:34:48.14Z</td>\n",
       "      <td>2016-12-04T15:35:06.90Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.PIEI..HH</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-04T15:34:48.00Z</td>\n",
       "      <td>2016-12-04T15:35:06.90Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.PIEI..HN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-04T15:34:43.69Z</td>\n",
       "      <td>2016-12-04T15:35:00.48Z</td>\n",
       "      <td>2016-12-04T15:35:07.35Z</td>\n",
       "      <td>1678</td>\n",
       "      <td>2366.0</td>\n",
       "      <td>11030611.IV.RM33..EH</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-04T15:34:44.38Z</td>\n",
       "      <td>2016-12-04T15:35:00.48Z</td>\n",
       "      <td>2016-12-04T15:35:07.35Z</td>\n",
       "      <td>1610</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>11030611.IV.RM33..HN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-12-04T15:34:40.30Z</td>\n",
       "      <td>2016-12-04T15:34:58.10Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.SEF1..HN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-12-04T15:34:40.10Z</td>\n",
       "      <td>2016-12-04T15:34:59.82Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.SNTG..HH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-12-04T15:34:39.70Z</td>\n",
       "      <td>2016-12-04T15:34:59.82Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.SNTG..HN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-12-04T15:34:44.28Z</td>\n",
       "      <td>2016-12-04T15:35:03.91Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.SSFR..HH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-12-04T15:34:44.87Z</td>\n",
       "      <td>2016-12-04T15:35:03.91Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11030611.IV.SSFR..HN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trace_start_time     trace_P_arrival_time     trace_S_arrival_time  \\\n",
       "0  2016-12-04T15:34:43.92Z  2016-12-04T15:35:01.27Z                      NaN   \n",
       "1  2016-12-04T15:34:48.14Z  2016-12-04T15:35:06.90Z                      NaN   \n",
       "2  2016-12-04T15:34:48.00Z  2016-12-04T15:35:06.90Z                      NaN   \n",
       "3  2016-12-04T15:34:43.69Z  2016-12-04T15:35:00.48Z  2016-12-04T15:35:07.35Z   \n",
       "4  2016-12-04T15:34:44.38Z  2016-12-04T15:35:00.48Z  2016-12-04T15:35:07.35Z   \n",
       "5  2016-12-04T15:34:40.30Z  2016-12-04T15:34:58.10Z                      NaN   \n",
       "6  2016-12-04T15:34:40.10Z  2016-12-04T15:34:59.82Z                      NaN   \n",
       "7  2016-12-04T15:34:39.70Z  2016-12-04T15:34:59.82Z                      NaN   \n",
       "8  2016-12-04T15:34:44.28Z  2016-12-04T15:35:03.91Z                      NaN   \n",
       "9  2016-12-04T15:34:44.87Z  2016-12-04T15:35:03.91Z                      NaN   \n",
       "\n",
       "   trace_P_arrival_sample  trace_S_arrival_sample            trace_name  \\\n",
       "0                    1735                     NaN  11030611.IV.OFFI..HH   \n",
       "1                    1876                     NaN  11030611.IV.PIEI..HH   \n",
       "2                    1889                     NaN  11030611.IV.PIEI..HN   \n",
       "3                    1678                  2366.0  11030611.IV.RM33..EH   \n",
       "4                    1610                  2297.0  11030611.IV.RM33..HN   \n",
       "5                    1780                     NaN  11030611.IV.SEF1..HN   \n",
       "6                    1971                     NaN  11030611.IV.SNTG..HH   \n",
       "7                    2012                     NaN  11030611.IV.SNTG..HN   \n",
       "8                    1962                     NaN  11030611.IV.SSFR..HH   \n",
       "9                    1903                     NaN  11030611.IV.SSFR..HN   \n",
       "\n",
       "   trace_GPD_P_number  trace_GPD_S_number  trace_EQT_number_detections  \\\n",
       "0                   1                   2                          1.0   \n",
       "1                   0                   2                          1.0   \n",
       "2                   2                   1                          NaN   \n",
       "3                   3                   7                          2.0   \n",
       "4                   1                   3                          NaN   \n",
       "5                   1                   1                          NaN   \n",
       "6                   1                   3                          2.0   \n",
       "7                   0                   4                          NaN   \n",
       "8                   1                   3                          1.0   \n",
       "9                   0                   4                          NaN   \n",
       "\n",
       "   trace_EQT_P_number  trace_EQT_S_number  \n",
       "0                 1.0                 1.0  \n",
       "1                 1.0                 1.0  \n",
       "2                 NaN                 NaN  \n",
       "3                 2.0                 2.0  \n",
       "4                 NaN                 NaN  \n",
       "5                 NaN                 NaN  \n",
       "6                 2.0                 2.0  \n",
       "7                 NaN                 NaN  \n",
       "8                 1.0                 1.0  \n",
       "9                 NaN                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_metadata = pd.read_csv(event_metadata_file, usecols=[\"trace_name\", 'trace_start_time', 'trace_P_arrival_time', 'trace_S_arrival_time', 'trace_P_arrival_sample', 'trace_S_arrival_sample', 'trace_GPD_P_number', 'trace_GPD_S_number', 'trace_EQT_P_number', 'trace_EQT_S_number', 'trace_EQT_number_detections'])\n",
    "\n",
    "event_metadata.head(10)\n",
    "# event_metadata.info(verbose=True)\n",
    "# event_metadata.describe()\n",
    "\n",
    "# test = event_metadata['trace_S_arrival_sample'] - event_metadata['trace_P_arrival_sample']\n",
    "# test.describe()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65e7f5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "=========================\n",
      "1032.0\n",
      "tensor(0.0010)\n",
      "torch.Size([3, 12000])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, event_metadata_file, noise_hdf5_file, noise_metadata_file, \"box_trapezoidal\", padding_type=\"percentage\", padding_value=1.5 )\n",
    "\n",
    "print(len(dataset))\n",
    "f1, t1 = dataset[3]\n",
    "print (\"=========================\")\n",
    "print((2366.0-1678)*1.5)\n",
    "print(t1[2366+1031])\n",
    "print(f1.shape)\n",
    "# print(f1[0, :10])\n",
    "# print (\"=========================\")\n",
    "# f1, t1 = dataset[10001]\n",
    "# print(t1)\n",
    "# print(f1.shape)\n",
    "# print(f1[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07198f-c559-4a08-a675-fb4e28a92eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############    Les trois canaux concaténés en ligne ################################### \n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(filename):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        if 'data' in f:\n",
    "            data = f['data']\n",
    "            if isinstance(data, h5py.Dataset):\n",
    "                print(\"Type du dataset 'data':\", type(data))\n",
    "                print(\"Forme du dataset 'data':\", data.shape)\n",
    "                data_matrix = data[:]  \n",
    "                print(\"Matrice de données:\", data_matrix)\n",
    "                return data_matrix\n",
    "            elif isinstance(data, h5py.Group):\n",
    "            \n",
    "                hdf5_data = []\n",
    "                trace_names = []\n",
    "                for key in data.keys():\n",
    "                    dataset = data[key]\n",
    "                    if isinstance(dataset, h5py.Dataset):\n",
    "                        # Vérifier la forme des données extraites\n",
    "                        if dataset.ndim == 2:\n",
    "                            # Concaténer les trois canaux pour chaque signal\n",
    "                            concatenated_data = np.concatenate([np.atleast_2d(dataset[i, :]) for i in range(3)], axis=1)\n",
    "                            hdf5_data.append(concatenated_data)\n",
    "                            trace_names.append(key)\n",
    "                        else:\n",
    "                            print(f\"Les données pour la clé '{key}' ne sont pas sous forme de tableau 2D.\")\n",
    "                if hdf5_data:\n",
    "                    stacked_data_matrix = np.vstack(hdf5_data)\n",
    "                    df_hdf5 = pd.DataFrame(stacked_data_matrix)\n",
    "                    df_hdf5['trace_name'] = trace_names\n",
    "                    return  df_hdf5\n",
    "\n",
    "\n",
    "# Utilisation de la fonction pour charger et convertir le dataset à partir du fichier HDF5\n",
    "filename1 = 'Instance_noise_1k.hdf5'\n",
    "df_noise = load_dataset(filename1)\n",
    "# Ajouter une colonne 'source_type' avec des valeurs constantes de 1\n",
    "df_noise['source_type'] = 1\n",
    "\n",
    "\n",
    "filename2 = 'Instance_events_counts_10k.hdf5'\n",
    "df_earth = load_dataset(filename2)\n",
    "len (df_earth)\n",
    "df_earth['source_type'] = 0\n",
    "print (df_earth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "16fcbbb8-7b2c-458f-a85d-9933446f0329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      source_id station_network_code station_code  station_location_code  \\\n",
      "0      11030611                   IV         OFFI                    NaN   \n",
      "1      11030611                   IV         PIEI                    NaN   \n",
      "2      11030611                   IV         PIEI                    NaN   \n",
      "3      11030611                   IV         RM33                    NaN   \n",
      "4      11030611                   IV         RM33                    NaN   \n",
      "...         ...                  ...          ...                    ...   \n",
      "9995   11282341                   IV         MPAG                    NaN   \n",
      "9996   11282341                   MN          BLY                    NaN   \n",
      "9997   11282341                   MN          BLY                    NaN   \n",
      "9998   11282341                   MN          CUC                    NaN   \n",
      "9999   11282341                   MN          CUC                    NaN   \n",
      "\n",
      "     station_channels  station_latitude_deg  station_longitude_deg  \\\n",
      "0                  HH              42.93500               13.68570   \n",
      "1                  HH              43.53567               12.53500   \n",
      "2                  HN              43.53567               12.53500   \n",
      "3                  EH              42.50898               13.21452   \n",
      "4                  HN              42.50898               13.21452   \n",
      "...               ...                   ...                    ...   \n",
      "9995               EH              43.62920               12.75950   \n",
      "9996               HH              44.74880               17.18390   \n",
      "9997               HL              44.74880               17.18390   \n",
      "9998               HH              39.99380               15.81550   \n",
      "9999               HN              39.99380               15.81550   \n",
      "\n",
      "      station_elevation_m  station_vs_30_mps          station_vs_30_detail  \\\n",
      "0                     320         580.000000  Vs30 extracted from ShakeMap   \n",
      "1                     665         778.339556  Vs30 extracted from ShakeMap   \n",
      "2                     665         778.339556  Vs30 extracted from ShakeMap   \n",
      "3                    1097         721.279254  Vs30 extracted from ShakeMap   \n",
      "4                    1097         721.279254  Vs30 extracted from ShakeMap   \n",
      "...                   ...                ...                           ...   \n",
      "9995                  930         579.192516  Vs30 extracted from ShakeMap   \n",
      "9996                  256         765.271418  Vs30 extracted from ShakeMap   \n",
      "9997                  256         765.271418  Vs30 extracted from ShakeMap   \n",
      "9998                  637         807.440158  Vs30 extracted from ShakeMap   \n",
      "9999                  637         807.440158  Vs30 extracted from ShakeMap   \n",
      "\n",
      "      ... trace_sa10_cmps2  trace_sa30_cmps2            trace_name  \\\n",
      "0     ...         0.001040          0.000094  11030611.IV.OFFI..HH   \n",
      "1     ...         0.000053          0.000015  11030611.IV.PIEI..HH   \n",
      "2     ...         0.000239          0.000078  11030611.IV.PIEI..HN   \n",
      "3     ...         0.000244          0.000055  11030611.IV.RM33..EH   \n",
      "4     ...         0.000301          0.000075  11030611.IV.RM33..HN   \n",
      "...   ...              ...               ...                   ...   \n",
      "9995  ...         0.005525          0.000803  11282341.IV.MPAG..EH   \n",
      "9996  ...         0.026140          0.001762   11282341.MN.BLY..HH   \n",
      "9997  ...         0.025938          0.001781   11282341.MN.BLY..HL   \n",
      "9998  ...         0.002233          0.000331   11282341.MN.CUC..HH   \n",
      "9999  ...         0.002003          0.000345   11282341.MN.CUC..HN   \n",
      "\n",
      "      trace_GPD_P_number  trace_GPD_S_number  trace_EQT_number_detections  \\\n",
      "0                      1                   2                          1.0   \n",
      "1                      0                   2                          1.0   \n",
      "2                      2                   1                          NaN   \n",
      "3                      3                   7                          2.0   \n",
      "4                      1                   3                          NaN   \n",
      "...                  ...                 ...                          ...   \n",
      "9995                   1                   1                          0.0   \n",
      "9996                   1                   1                          1.0   \n",
      "9997                   1                   1                          NaN   \n",
      "9998                   1                   2                          1.0   \n",
      "9999                   0                   2                          NaN   \n",
      "\n",
      "      trace_EQT_P_number  trace_EQT_S_number  trace_deconvolved_units  \\\n",
      "0                    1.0                 1.0                      mps   \n",
      "1                    1.0                 1.0                      mps   \n",
      "2                    NaN                 NaN                     mps2   \n",
      "3                    2.0                 2.0                      mps   \n",
      "4                    NaN                 NaN                     mps2   \n",
      "...                  ...                 ...                      ...   \n",
      "9995                 0.0                 0.0                      mps   \n",
      "9996                 1.0                 1.0                      mps   \n",
      "9997                 NaN                 NaN                     mps2   \n",
      "9998                 1.0                 0.0                      mps   \n",
      "9999                 NaN                 NaN                     mps2   \n",
      "\n",
      "      source_type  \n",
      "0      earthquake  \n",
      "1      earthquake  \n",
      "2      earthquake  \n",
      "3      earthquake  \n",
      "4      earthquake  \n",
      "...           ...  \n",
      "9995   earthquake  \n",
      "9996   earthquake  \n",
      "9997   earthquake  \n",
      "9998   earthquake  \n",
      "9999   earthquake  \n",
      "\n",
      "[10000 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################    récuperation des données dans les csv \n",
    "\n",
    "\n",
    "# Spécifier le chemin complet vers le fichier CSV\n",
    "csv_file1 = 'metadata_Instance_noise_1k.csv'\n",
    "# Lecture du fichier CSV contenant les informations sur la base de données des signaux\n",
    "noise_csv = pd.read_csv(csv_file1)\n",
    "\n",
    "# Spécifier le chemin complet vers le fichier CSV\n",
    "csv_file2 = 'metadata_Instance_events_10k.csv'\n",
    "# Lecture du fichier CSV contenant les informations sur la base de données des signaux\n",
    "earth_csv = pd.read_csv(csv_file2)\n",
    "print(earth_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95077e31-f845-4cf6-ba8e-b448ab281524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e6e74780-2b0b-4faa-852e-50fd6f3e453c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'station_network_code', 'station_code',\n",
      "       'station_location_code', 'station_channels', 'station_latitude_deg',\n",
      "       'station_longitude_deg', 'station_elevation_m', 'station_vs_30_mps',\n",
      "       'station_vs_30_detail', 'trace_start_time', 'trace_dt_s', 'trace_npts',\n",
      "       'trace_E_median_counts', 'trace_N_median_counts',\n",
      "       'trace_Z_median_counts', 'trace_E_mean_counts', 'trace_N_mean_counts',\n",
      "       'trace_Z_mean_counts', 'trace_E_min_counts', 'trace_N_min_counts',\n",
      "       'trace_Z_min_counts', 'trace_E_max_counts', 'trace_N_max_counts',\n",
      "       'trace_Z_max_counts', 'trace_E_rms_counts', 'trace_N_rms_counts',\n",
      "       'trace_Z_rms_counts', 'trace_E_lower_quartile_counts',\n",
      "       'trace_N_lower_quartile_counts', 'trace_Z_lower_quartile_counts',\n",
      "       'trace_E_upper_quartile_counts', 'trace_N_upper_quartile_counts',\n",
      "       'trace_Z_upper_quartile_counts', 'trace_E_spikes', 'trace_N_spikes',\n",
      "       'trace_Z_spikes', 'trace_name', 'trace_GPD_P_number',\n",
      "       'trace_GPD_S_number', 'trace_EQT_number_detections',\n",
      "       'trace_EQT_P_number', 'trace_EQT_S_number'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################    récuperation des nom de colonnes en commun dans le csv de noise et earthquake\n",
    "\n",
    "def  common_columns(csv_file1,csv_file2):\n",
    "\n",
    "    earth_csv = pd.read_csv(csv_file1) \n",
    "    noise_csv = pd.read_csv(csv_file2)\n",
    "    # Obtenir les noms de colonnes en commun\n",
    "    common_columns = earth_csv.columns.intersection(noise_csv.columns)\n",
    "    # Afficher les noms de colonnes en commun\n",
    "    print(common_columns)\n",
    "\n",
    "# Spécifier le chemin complet vers le fichier CSV\n",
    "csv_file1 = 'metadata_Instance_events_10k.csv'\n",
    "# Spécifier le chemin complet vers le fichier CSV\n",
    "csv_file2 = 'metadata_Instance_noise_1k.csv'\n",
    "\n",
    "common_columns(csv_file1,csv_file2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b38e2-2f96-4998-8ab4-fd4547727b79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
