{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9638787b-eb90-44d3-8c50-1427bd34f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.dataloaders.InstanceDataset import InstanceDataset\n",
    "from utils.plot import plot_trace_prediction\n",
    "import torch\n",
    "import math\n",
    "import h5py\n",
    "from torchinfo import summary \n",
    "from nn.eq_transformer import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6916fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_hdf5_file = \"data/instance_samples/Instance_events_counts_10k.hdf5\"\n",
    "# event_metadata_file = \"data/instance_samples/metadata_Instance_events_10k.csv\"\n",
    "# noise_hdf5_file = \"data/instance_samples/Instance_noise_1k.hdf5\"\n",
    "# noise_metadata_file = \"data/instance_samples/metadata_Instance_noise_1k.csv\"\n",
    "\n",
    "event_hdf5_file = \"data/instance_samples/earthquake_20k.hdf5\"\n",
    "event_metadata_file = \"data/instance_samples/earthquake_20k.csv\"\n",
    "noise_hdf5_file = \"data/instance_samples/noise_20k.hdf5\"\n",
    "noise_metadata_file = \"data/instance_samples/noise_20k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b7d389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _shuffle_events(event_metadata_file, noise_metadata_file, random_state, output_event_metadata_file, output_noise_metadata_file, balance=False, remove_empty_phase=False):\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Split the list of input data into training, validation, and test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    event_metadata_file: str\n",
    "        path to event metadata file \n",
    "    \n",
    "    noise_metadata_file: str\n",
    "        path to event metadata file \n",
    "\n",
    "    random_state: int\n",
    "        random state for reproducibility\n",
    "\n",
    "    output_event_metadata_file: bool\n",
    "       Path to the output event metadata file\n",
    "\n",
    "    output_noise_metadata_file: str\n",
    "       Path to the output noise metadata file\n",
    "\n",
    "    balance: bool\n",
    "       Should have equal noise and events \n",
    "\n",
    "    remove_empty_phase: bool\n",
    "       Remove events that do not have both phases\n",
    "              \n",
    "    Returns\n",
    "    -------   \n",
    "    (output_event_metadata_file, output_noise_metadata_file)\n",
    "    \"\"\"       \n",
    "\n",
    "    noise_metadata = pd.read_csv(noise_metadata_file)\n",
    "    event_metadata = pd.read_csv(event_metadata_file, usecols=[\"trace_name\", 'trace_start_time', 'trace_P_arrival_time', 'trace_S_arrival_time', 'trace_P_arrival_sample', 'trace_S_arrival_sample', 'trace_GPD_P_number', 'trace_GPD_S_number', 'trace_EQT_P_number', 'trace_EQT_S_number', 'trace_EQT_number_detections'])\n",
    "\n",
    "    if remove_empty_phase:\n",
    "        event_metadata = event_metadata[event_metadata[\"trace_P_arrival_sample\"].notna() & event_metadata[\"trace_S_arrival_sample\"].notna()]\n",
    "    \n",
    "    event_metadata = event_metadata.sample(frac=1, random_state=random_state) \n",
    "    noise_metadata = noise_metadata.sample(frac=1, random_state=random_state) \n",
    "\n",
    "    if balance:\n",
    "        min_count = min(event_metadata.shape[0], noise_metadata.shape[0])\n",
    "        event_metadata = event_metadata.head(min_count)\n",
    "        noise_metadata = noise_metadata.head(min_count)\n",
    "\n",
    "    event_metadata.to_csv(output_event_metadata_file, index=False)\n",
    "    noise_metadata.to_csv(output_noise_metadata_file, index=False)\n",
    "\n",
    "    return output_event_metadata_file, output_noise_metadata_file \n",
    "\n",
    "\n",
    "shuffled_event_metadata_file, shuffled_noise_metadata_file = _shuffle_events(\n",
    "    event_metadata_file=event_metadata_file,\n",
    "    noise_metadata_file=noise_metadata_file,\n",
    "    random_state=9,\n",
    "    output_event_metadata_file='temp/event_metadata.csv',\n",
    "    output_noise_metadata_file='temp/noise_metadata.csv',\n",
    "    balance=True,\n",
    "    remove_empty_phase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c04581c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_P_arrival_time</th>\n",
       "      <th>trace_S_arrival_time</th>\n",
       "      <th>trace_P_arrival_sample</th>\n",
       "      <th>trace_S_arrival_sample</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>trace_GPD_P_number</th>\n",
       "      <th>trace_GPD_S_number</th>\n",
       "      <th>trace_EQT_number_detections</th>\n",
       "      <th>trace_EQT_P_number</th>\n",
       "      <th>trace_EQT_S_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-11-19T17:07:47.00Z</td>\n",
       "      <td>2016-11-19T17:08:03.75Z</td>\n",
       "      <td>2016-11-19T17:08:10.47Z</td>\n",
       "      <td>1675</td>\n",
       "      <td>2347.0</td>\n",
       "      <td>10220691.IV.LNSS..HH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-11-20T01:41:35.53Z</td>\n",
       "      <td>2016-11-20T01:41:55.05Z</td>\n",
       "      <td>2016-11-20T01:41:56.60Z</td>\n",
       "      <td>1952</td>\n",
       "      <td>2107.0</td>\n",
       "      <td>10239411.IV.T1299..EH</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-11-21T03:45:47.84Z</td>\n",
       "      <td>2016-11-21T03:46:06.14Z</td>\n",
       "      <td>2016-11-21T03:46:14.25Z</td>\n",
       "      <td>1830</td>\n",
       "      <td>2641.0</td>\n",
       "      <td>10299921.IV.CESX..HH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-11-18T00:09:43.93Z</td>\n",
       "      <td>2016-11-18T00:10:02.27Z</td>\n",
       "      <td>2016-11-18T00:10:11.94Z</td>\n",
       "      <td>1834</td>\n",
       "      <td>2801.0</td>\n",
       "      <td>10128831.IV.FIAM..HN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-11-19T21:53:23.98Z</td>\n",
       "      <td>2016-11-19T21:53:44.94Z</td>\n",
       "      <td>2016-11-19T21:53:48.33Z</td>\n",
       "      <td>2096</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>10230551.IV.LNSS..HH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-11-16T02:59:59.93Z</td>\n",
       "      <td>2016-11-16T03:00:17.15Z</td>\n",
       "      <td>2016-11-16T03:00:20.15Z</td>\n",
       "      <td>1721</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10004521.IV.SSM1..HN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-11-22T01:28:01.85Z</td>\n",
       "      <td>2016-11-22T01:28:21.34Z</td>\n",
       "      <td>2016-11-22T01:28:27.65Z</td>\n",
       "      <td>1948</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>10350381.IV.T1256..HN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-11-18T17:55:03.37Z</td>\n",
       "      <td>2016-11-18T17:55:22.75Z</td>\n",
       "      <td>2016-11-18T17:55:26.55Z</td>\n",
       "      <td>1937</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>10171861.IV.GUMA..HH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-11-16T15:07:58.35Z</td>\n",
       "      <td>2016-11-16T15:08:16.67Z</td>\n",
       "      <td>2016-11-16T15:08:21.85Z</td>\n",
       "      <td>1832</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>10037661.IV.T1247..HH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-11-20T19:21:16.26Z</td>\n",
       "      <td>2016-11-20T19:21:34.69Z</td>\n",
       "      <td>2016-11-20T19:21:41.30Z</td>\n",
       "      <td>1843</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>10280601.IV.LNSS..HH</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          trace_start_time     trace_P_arrival_time     trace_S_arrival_time  \\\n",
       "0  2016-11-19T17:07:47.00Z  2016-11-19T17:08:03.75Z  2016-11-19T17:08:10.47Z   \n",
       "1  2016-11-20T01:41:35.53Z  2016-11-20T01:41:55.05Z  2016-11-20T01:41:56.60Z   \n",
       "2  2016-11-21T03:45:47.84Z  2016-11-21T03:46:06.14Z  2016-11-21T03:46:14.25Z   \n",
       "3  2016-11-18T00:09:43.93Z  2016-11-18T00:10:02.27Z  2016-11-18T00:10:11.94Z   \n",
       "4  2016-11-19T21:53:23.98Z  2016-11-19T21:53:44.94Z  2016-11-19T21:53:48.33Z   \n",
       "5  2016-11-16T02:59:59.93Z  2016-11-16T03:00:17.15Z  2016-11-16T03:00:20.15Z   \n",
       "6  2016-11-22T01:28:01.85Z  2016-11-22T01:28:21.34Z  2016-11-22T01:28:27.65Z   \n",
       "7  2016-11-18T17:55:03.37Z  2016-11-18T17:55:22.75Z  2016-11-18T17:55:26.55Z   \n",
       "8  2016-11-16T15:07:58.35Z  2016-11-16T15:08:16.67Z  2016-11-16T15:08:21.85Z   \n",
       "9  2016-11-20T19:21:16.26Z  2016-11-20T19:21:34.69Z  2016-11-20T19:21:41.30Z   \n",
       "\n",
       "   trace_P_arrival_sample  trace_S_arrival_sample             trace_name  \\\n",
       "0                    1675                  2347.0   10220691.IV.LNSS..HH   \n",
       "1                    1952                  2107.0  10239411.IV.T1299..EH   \n",
       "2                    1830                  2641.0   10299921.IV.CESX..HH   \n",
       "3                    1834                  2801.0   10128831.IV.FIAM..HN   \n",
       "4                    2096                  2435.0   10230551.IV.LNSS..HH   \n",
       "5                    1721                  2021.0   10004521.IV.SSM1..HN   \n",
       "6                    1948                  2580.0  10350381.IV.T1256..HN   \n",
       "7                    1937                  2318.0   10171861.IV.GUMA..HH   \n",
       "8                    1832                  2350.0  10037661.IV.T1247..HH   \n",
       "9                    1843                  2504.0   10280601.IV.LNSS..HH   \n",
       "\n",
       "   trace_GPD_P_number  trace_GPD_S_number  trace_EQT_number_detections  \\\n",
       "0                 0.0                 3.0                          3.0   \n",
       "1                 2.0                 2.0                          1.0   \n",
       "2                 1.0                 1.0                          1.0   \n",
       "3                 NaN                 NaN                          NaN   \n",
       "4                 1.0                 4.0                          1.0   \n",
       "5                 NaN                 NaN                          NaN   \n",
       "6                 NaN                 NaN                          NaN   \n",
       "7                 1.0                 3.0                          1.0   \n",
       "8                 1.0                 1.0                          1.0   \n",
       "9                 0.0                 3.0                          1.0   \n",
       "\n",
       "   trace_EQT_P_number  trace_EQT_S_number  \n",
       "0                 3.0                 2.0  \n",
       "1                 1.0                 1.0  \n",
       "2                 1.0                 1.0  \n",
       "3                 NaN                 NaN  \n",
       "4                 1.0                 1.0  \n",
       "5                 NaN                 NaN  \n",
       "6                 NaN                 NaN  \n",
       "7                 1.0                 1.0  \n",
       "8                 1.0                 1.0  \n",
       "9                 1.0                 1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_metadata = pd.read_csv(shuffled_event_metadata_file, usecols=[\"trace_name\", 'trace_start_time', 'trace_P_arrival_time', 'trace_S_arrival_time', 'trace_P_arrival_sample', 'trace_S_arrival_sample', 'trace_GPD_P_number', 'trace_GPD_S_number', 'trace_EQT_P_number', 'trace_EQT_S_number', 'trace_EQT_number_detections'])\n",
    "\n",
    "event_metadata = event_metadata[event_metadata[\"trace_P_arrival_sample\"].notna() & event_metadata[\"trace_S_arrival_sample\"].notna()]\n",
    "\n",
    "event_metadata.head(10)\n",
    "# event_metadata.info(verbose=True)\n",
    "# event_metadata.describe()\n",
    "# event_metadata.shape\n",
    "\n",
    "# test = event_metadata['trace_S_arrival_sample'] - event_metadata['trace_P_arrival_sample']\n",
    "# test.describe()\n",
    "\n",
    "# print(event_metadata[\"trace_name\"].iloc[4969])\n",
    "# print(event_metadata[\"trace_P_arrival_sample\"][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abdceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>station_network_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>station_location_code</th>\n",
       "      <th>station_channels</th>\n",
       "      <th>station_latitude_deg</th>\n",
       "      <th>station_longitude_deg</th>\n",
       "      <th>station_elevation_m</th>\n",
       "      <th>station_vs_30_mps</th>\n",
       "      <th>station_vs_30_detail</th>\n",
       "      <th>...</th>\n",
       "      <th>trace_Z_upper_quartile_counts</th>\n",
       "      <th>trace_E_spikes</th>\n",
       "      <th>trace_N_spikes</th>\n",
       "      <th>trace_Z_spikes</th>\n",
       "      <th>trace_name</th>\n",
       "      <th>trace_GPD_P_number</th>\n",
       "      <th>trace_GPD_S_number</th>\n",
       "      <th>trace_EQT_number_detections</th>\n",
       "      <th>trace_EQT_P_number</th>\n",
       "      <th>trace_EQT_S_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20060912T030438</td>\n",
       "      <td>IV</td>\n",
       "      <td>VVLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EH</td>\n",
       "      <td>41.86965</td>\n",
       "      <td>13.62324</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Vs30 extracted from ShakeMap</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20060912T030438.IV.VVLD..EH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090520T062013</td>\n",
       "      <td>IV</td>\n",
       "      <td>T0104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EH</td>\n",
       "      <td>42.35990</td>\n",
       "      <td>13.33820</td>\n",
       "      <td>754.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>Vs30 extracted from ShakeMap</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20090520T062013.IV.T0104..EH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090317T025034</td>\n",
       "      <td>IV</td>\n",
       "      <td>VVLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HH</td>\n",
       "      <td>41.86965</td>\n",
       "      <td>13.62324</td>\n",
       "      <td>1051.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>Vs30 extracted from ShakeMap</td>\n",
       "      <td>...</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20090317T025034.IV.VVLD..HH</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090613T122035</td>\n",
       "      <td>IV</td>\n",
       "      <td>CSNT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HH</td>\n",
       "      <td>43.47311</td>\n",
       "      <td>11.29017</td>\n",
       "      <td>636.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>Vs30 extracted from ShakeMap</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20090613T122035.IV.CSNT..HH</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20080930T112359</td>\n",
       "      <td>IV</td>\n",
       "      <td>IVPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HH</td>\n",
       "      <td>38.37630</td>\n",
       "      <td>14.98010</td>\n",
       "      <td>486.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>Vs30 extracted from ShakeMap</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20080930T112359.IV.IVPL..HH</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         source_id station_network_code station_code  station_location_code  \\\n",
       "0  20060912T030438                   IV         VVLD                    NaN   \n",
       "1  20090520T062013                   IV        T0104                    NaN   \n",
       "2  20090317T025034                   IV         VVLD                    NaN   \n",
       "3  20090613T122035                   IV         CSNT                    NaN   \n",
       "4  20080930T112359                   IV         IVPL                    NaN   \n",
       "\n",
       "  station_channels  station_latitude_deg  station_longitude_deg  \\\n",
       "0               EH              41.86965               13.62324   \n",
       "1               EH              42.35990               13.33820   \n",
       "2               HH              41.86965               13.62324   \n",
       "3               HH              43.47311               11.29017   \n",
       "4               HH              38.37630               14.98010   \n",
       "\n",
       "   station_elevation_m  station_vs_30_mps          station_vs_30_detail  ...  \\\n",
       "0               1051.0              505.0  Vs30 extracted from ShakeMap  ...   \n",
       "1                754.0              473.0  Vs30 extracted from ShakeMap  ...   \n",
       "2               1051.0              505.0  Vs30 extracted from ShakeMap  ...   \n",
       "3                636.0              580.0  Vs30 extracted from ShakeMap  ...   \n",
       "4                486.0              664.0  Vs30 extracted from ShakeMap  ...   \n",
       "\n",
       "  trace_Z_upper_quartile_counts  trace_E_spikes  trace_N_spikes  \\\n",
       "0                          21.0             0.0             0.0   \n",
       "1                          42.0             0.0             0.0   \n",
       "2                         143.0             0.0             0.0   \n",
       "3                          29.0             0.0             0.0   \n",
       "4                          35.0             0.0             0.0   \n",
       "\n",
       "   trace_Z_spikes                    trace_name  trace_GPD_P_number  \\\n",
       "0             0.0   20060912T030438.IV.VVLD..EH                   0   \n",
       "1             0.0  20090520T062013.IV.T0104..EH                   0   \n",
       "2             0.0   20090317T025034.IV.VVLD..HH                   0   \n",
       "3             0.0   20090613T122035.IV.CSNT..HH                   1   \n",
       "4             0.0   20080930T112359.IV.IVPL..HH                   0   \n",
       "\n",
       "   trace_GPD_S_number  trace_EQT_number_detections  trace_EQT_P_number  \\\n",
       "0                   0                          0.0                 0.0   \n",
       "1                   1                          0.0                 0.0   \n",
       "2                   0                          0.0                 0.0   \n",
       "3                   3                          0.0                 0.0   \n",
       "4                   1                          0.0                 0.0   \n",
       "\n",
       "   trace_EQT_S_number  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_metadata = pd.read_csv(shuffled_noise_metadata_file)\n",
    "\n",
    "noise_metadata.head()\n",
    "\n",
    "# print(noise_metadata[\"trace_name\"].iloc[170])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea730617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size = 28014\n",
      "################## Accessing first event ##################\n",
      "index = 0\n",
      "Detection target = 1\n",
      "input shape = torch.Size([3, 12000])\n",
      "trace name = 10220691.IV.LNSS..HH\n",
      "################## Accessing last event ##################\n",
      "index = 14006\n",
      "Detection target = 1\n",
      "input shape = torch.Size([3, 12000])\n",
      "trace name = 10243491.IV.T1245..HN\n",
      "################## Accessing first noise ##################\n",
      "index = 14007\n",
      "Detection target = 0\n",
      "input shape = torch.Size([3, 12000])\n",
      "trace name = 20060912T030438.IV.VVLD..EH\n",
      "################## Accessing last noise ##################\n",
      "index = 28013\n",
      "Detection target = 0\n",
      "input shape = torch.Size([3, 12000])\n",
      "trace name = 20080914T010641.IV.MODR..HH\n",
      "################## Out of Index ##################\n",
      "index = 28014\n",
      "Detection target = 0\n",
      "input shape = torch.Size([3, 12000])\n",
      "trace name = 20060912T030438.IV.VVLD..EH\n"
     ]
    }
   ],
   "source": [
    "#Pass split percentage = [1] to not split and access the whole data\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", split_index=0, split_percentage=[1], padding_type=\"sample\", start_padding_value=100, end_padding_value=1000, target_phase=True, phase_padding=20)\n",
    "\n",
    "print(f\"Dataset size = {len(dataset)}\")\n",
    "\n",
    "print(\"################## Accessing first event ##################\")\n",
    "index = 0\n",
    "f1, t1, p1, s1, trace_name = dataset[index]\n",
    "print(f\"index = {index}\")\n",
    "print(f\"Detection target = {t1}\")\n",
    "print(f\"input shape = {f1.shape}\")\n",
    "print(f\"trace name = {trace_name}\")\n",
    "\n",
    "print(\"################## Accessing last event ##################\")\n",
    "index = event_metadata.shape[0] - 1\n",
    "f1, t1, p1, s1, trace_name = dataset[index]\n",
    "print(f\"index = {index}\")\n",
    "print(f\"Detection target = {t1}\")\n",
    "print(f\"input shape = {f1.shape}\")\n",
    "print(f\"trace name = {trace_name}\")\n",
    "\n",
    "\n",
    "print(\"################## Accessing first noise ##################\")\n",
    "index = event_metadata.shape[0]\n",
    "f1, t1, p1, s1, trace_name = dataset[index]\n",
    "print(f\"index = {index}\")\n",
    "print(f\"Detection target = {t1}\")\n",
    "print(f\"input shape = {f1.shape}\")\n",
    "print(f\"trace name = {trace_name}\")\n",
    "\n",
    "\n",
    "print(\"################## Accessing last noise ##################\")\n",
    "index = noise_metadata.shape[0] + event_metadata.shape[0] - 1\n",
    "f1, t1, p1, s1, trace_name = dataset[index]\n",
    "print(f\"index = {index}\")\n",
    "print(f\"Detection target = {t1}\")\n",
    "print(f\"input shape = {f1.shape}\")\n",
    "print(f\"trace name = {trace_name}\")\n",
    "\n",
    "print(\"################## Out of Index ##################\")\n",
    "index = noise_metadata.shape[0] + event_metadata.shape[0]\n",
    "print(f\"index = {index}\")\n",
    "f1, t1, p1, s1, trace_name = dataset[index]\n",
    "print(f\"Detection target = {t1}\")\n",
    "print(f\"input shape = {f1.shape}\")\n",
    "print(f\"trace name = {trace_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3c_wave_form(filename, trace_name):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        return torch.FloatTensor(f['data'][trace_name][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65e7f5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size - Expected:23810 - Actual:23810\n",
      "Val size - Expected:1400 - Actual:1400\n",
      "Test size - Expected:2800 - Actual:2800\n",
      "Train first event data matches: True\n",
      "Train first target matches: True\n",
      "Train first noise data matches: True\n",
      "Train first noise target matches: True\n",
      "Train last event data matches: True\n",
      "Train last event target matches: True\n",
      "Train last noise data matches: True\n",
      "Train last noise target matches: True\n",
      "Val first event data matches: True\n",
      "Val first target matches: True\n",
      "Val first noise data matches: True\n",
      "Val first noise target matches: True\n",
      "Val last event data matches: True\n",
      "Val last event target matches: True\n",
      "Val last noise data matches: True\n",
      "Val last noise target matches: True\n",
      "Test first event data matches: True\n",
      "Test first target matches: True\n",
      "Test first noise data matches: True\n",
      "Test first noise target matches: True\n",
      "Test last event data matches: True\n",
      "Test last event target matches: True\n",
      "Test last noise data matches: True\n",
      "Test last noise target matches: True\n"
     ]
    }
   ],
   "source": [
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[0.85, 0.05, 0.1]\n",
    "\n",
    "train_dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", split_index=0, split_percentage=split_percentage, padding_type=\"sample\", start_padding_value=100, end_padding_value=1000, target_phase=False, phase_padding=20)\n",
    "val_dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", split_index=1, split_percentage=split_percentage, padding_type=\"sample\", start_padding_value=100, end_padding_value=1000, target_phase=False, phase_padding=20)\n",
    "test_dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", split_index=2, split_percentage=split_percentage, padding_type=\"sample\", start_padding_value=100, end_padding_value=1000, target_phase=False, phase_padding=20)\n",
    "\n",
    "#Check dataset sizes\n",
    "train_events_count = math.floor(event_metadata.shape[0] * split_percentage[0])\n",
    "train_noise_count = math.floor(noise_metadata.shape[0] * split_percentage[0])\n",
    "print(f\"Train size - Expected:{train_events_count+train_noise_count} - Actual:{len(train_dataset)}\")\n",
    "\n",
    "\n",
    "val_events_count = math.floor(event_metadata.shape[0] * split_percentage[1])\n",
    "val_noise_count = math.floor(noise_metadata.shape[0] * split_percentage[1])\n",
    "print(f\"Val size - Expected:{val_events_count+val_noise_count} - Actual:{len(val_dataset)}\")\n",
    "\n",
    "\n",
    "test_events_count = math.floor(event_metadata.shape[0] * split_percentage[2])\n",
    "test_noise_count = math.floor(noise_metadata.shape[0] * split_percentage[2])\n",
    "print(f\"Test size - Expected:{test_events_count+test_noise_count} - Actual:{len(test_dataset)}\")\n",
    "\n",
    "\n",
    "#Check train dataset indexes\n",
    "absolute_index = 0\n",
    "data, target, p, s, name = train_dataset[0]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Train first event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Train first target matches: {target == 1}\")\n",
    "\n",
    "data, target, p, s, name = train_dataset[train_events_count]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Train first noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Train first noise target matches: {target == 0}\")\n",
    "\n",
    "absolute_index = train_events_count - 1\n",
    "data, target, p, s, name = train_dataset[train_events_count - 1]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Train last event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Train last event target matches: {target == 1}\")\n",
    "\n",
    "absolute_index = train_noise_count - 1\n",
    "data, target, p, s, name = train_dataset[train_events_count + train_noise_count - 1]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Train last noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Train last noise target matches: {target == 0}\")\n",
    "\n",
    "#Check validation dataset indexes\n",
    "absolute_index = train_events_count\n",
    "data, target, p, s, name = val_dataset[0]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Val first event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Val first target matches: {target == 1}\")\n",
    "\n",
    "absolute_index = train_noise_count\n",
    "data, target, p, s, name = val_dataset[val_events_count]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Val first noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Val first noise target matches: {target == 0}\")\n",
    "\n",
    "absolute_index = train_events_count + val_events_count - 1\n",
    "data, target, p, s, name = val_dataset[val_events_count - 1]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Val last event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Val last event target matches: {target == 1}\")\n",
    "\n",
    "absolute_index = train_noise_count + val_noise_count - 1\n",
    "data, target, p, s, name = val_dataset[val_events_count + val_noise_count - 1]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Val last noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Val last noise target matches: {target == 0}\")\n",
    "\n",
    "#Check test dataset indexes\n",
    "absolute_index = train_events_count + val_events_count\n",
    "data, target, p, s, name = test_dataset[0]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Test first event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Test first target matches: {target == 1}\")\n",
    "\n",
    "absolute_index = train_noise_count + val_noise_count\n",
    "data, target, p, s, name = test_dataset[test_events_count]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Test first noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Test first noise target matches: {target == 0}\")\n",
    "\n",
    "absolute_index = train_events_count + val_events_count + test_events_count - 1\n",
    "data, target, p, s, name = test_dataset[test_events_count - 1]\n",
    "actual_data = get_3c_wave_form(event_hdf5_file, event_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Test last event data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Test last event target matches: {target == 1}\")\n",
    "\n",
    "absolute_index = train_noise_count + val_noise_count + test_noise_count - 1\n",
    "data, target, p, s, name = test_dataset[test_events_count + test_noise_count - 1]\n",
    "actual_data = get_3c_wave_form(noise_hdf5_file, noise_metadata[\"trace_name\"].iloc[absolute_index])\n",
    "print(f\"Test last noise data matches: {torch.equal(data, actual_data)}\")\n",
    "print(f\"Test last noise target matches: {target == 0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95077e31-f845-4cf6-ba8e-b448ab281524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekabore/Documents/personal/school/H2024/IFT6759/earthquake/utils/plot.py:163: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[0.85, 0.05, 0.1]\n",
    "split_index = 0\n",
    "\n",
    "index = 102\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"box_square\", padding_type=\"percentage\", start_padding_value=0, end_padding_value=1.4, target_phase=True, phase_padding=20, split_index=split_index, split_percentage=split_percentage)\n",
    "\n",
    "\n",
    "trace_name = f'{event_metadata[\"trace_name\"].iloc[index]}-square-sample'\n",
    "p_sample = event_metadata[\"trace_P_arrival_sample\"].iloc[index]\n",
    "s_sample = event_metadata[\"trace_S_arrival_sample\"].iloc[index]\n",
    "input, target, p_target, s_target, name = dataset[index]\n",
    "\n",
    "sample_size = input.shape[1]\n",
    "\n",
    "if np.isnan(p_sample):\n",
    "    p_sample = 0\n",
    "\n",
    "if np.isnan(s_sample):\n",
    "    s_sample = sample_size - 1\n",
    "\n",
    "s_sample = round(s_sample)\n",
    "\n",
    "plot_trace_prediction(trace_name, input, np.array([p_sample]), np.array([s_sample]), target, p_target, s_target, \"output/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88528d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekabore/Documents/personal/school/H2024/IFT6759/earthquake/utils/plot.py:163: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[0.85, 0.05, 0.1]\n",
    "split_index = 0\n",
    "\n",
    "index = 5\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", padding_type=\"sample\", start_padding_value=40, end_padding_value=40, target_phase=False, phase_padding=100, split_index=split_index, split_percentage=split_percentage)\n",
    "\n",
    "\n",
    "trace_name = f'{event_metadata[\"trace_name\"].iloc[index]}-square-sample'\n",
    "p_sample = event_metadata[\"trace_P_arrival_sample\"].iloc[index]\n",
    "s_sample = event_metadata[\"trace_S_arrival_sample\"].iloc[index]\n",
    "input, target, p_target, s_target, _ = dataset[index]\n",
    "\n",
    "sample_size = input.shape[1]\n",
    "\n",
    "if np.isnan(p_sample):\n",
    "    p_sample = 0\n",
    "\n",
    "if np.isnan(s_sample):\n",
    "    s_sample = sample_size - 1\n",
    "\n",
    "s_sample = round(s_sample)\n",
    "\n",
    "plot_trace_prediction(trace_name, input, np.array([p_sample]), np.array([s_sample]), target, p_target, s_target, \"output/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d226129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=0\n",
      "5\n",
      "torch.Size([3, 12000])\n",
      "tensor(1)\n",
      "tensor(-1)\n",
      "tensor(-1)\n",
      "Print data are good\n",
      "=============\n",
      "y: 1 - trace name: 10210101.IV.SSFR..HN\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 0 - trace name: 20100120T120736.GU.BHB..HH\n",
      "Data is noise and matches: True\n",
      "=============\n",
      "y: 0 - trace name: 20090827T225325.IV.RMP..HH\n",
      "Data is noise and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10281481.IV.T1256..HN\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 0 - trace name: 20080129T190140.IV.SCTE..HH\n",
      "Data is noise and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10126201.IV.T1216..EH\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10308001.IV.T1219..EH\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10284211.IV.GUMA..HN\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10340251.IV.CESI..HH\n",
      "Data is signal and matches: True\n",
      "=============\n",
      "y: 1 - trace name: 10103471.IV.T1241..HN\n",
      "Data is signal and matches: True\n"
     ]
    }
   ],
   "source": [
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[0.85, 0.05, 0.1]\n",
    "split_index = 0\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", padding_type=\"sample\", start_padding_value=40, end_padding_value=40, target_phase=False, phase_padding=100, remove_empty_phase=False, split_index=split_index, split_percentage=split_percentage)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=10, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f'index={i}')\n",
    "    #batch[0][i] == tensor 3x12000 of the data of the i element\n",
    "    #batch[1][i] == target of i element\n",
    "    #batch[2][i] == p_target of i element\n",
    "    #batch[3][i] == s_target of i element\n",
    "    print(len(batch))\n",
    "    print(batch[0][0].size())\n",
    "    print(batch[1][0])\n",
    "    print(batch[2][0])\n",
    "    print(batch[3][0])\n",
    "\n",
    "    data = batch[0]\n",
    "    targets = batch[1]\n",
    "    trace_names = batch[4]\n",
    "    break\n",
    "\n",
    "print(\"Print data are good\")\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    print(\"=============\")\n",
    "    trace_name = trace_names[i]\n",
    "    y = targets[i]\n",
    "    print(f\"y: {y} - trace name: {trace_name}\")\n",
    "    if y == 0:\n",
    "        actual_data = get_3c_wave_form(noise_hdf5_file, trace_name)\n",
    "        print(f\"Data is noise and matches: {torch.equal(data[i], actual_data)}\")\n",
    "    else:\n",
    "        actual_data = get_3c_wave_form(event_hdf5_file, trace_name)\n",
    "        print(f\"Data is signal and matches: {torch.equal(data[i], actual_data)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "252f5c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=127, data size=128, hasNoise=True, hasEvent=True everything is good!\n",
      "index=19, data size=20, hasNoise=True, hasEvent=True everything is good!\n"
     ]
    }
   ],
   "source": [
    "#Check data are loading properly\n",
    "\n",
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[0.91, 0.04, 0.05]\n",
    "split_index = 0\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, shuffled_event_metadata_file, noise_hdf5_file, shuffled_noise_metadata_file, \"binary\", padding_type=\"sample\", start_padding_value=40, end_padding_value=40, target_phase=False, phase_padding=100, remove_empty_phase=True, split_index=split_index, split_percentage=split_percentage)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=128, shuffle=True, num_workers=2\n",
    ")\n",
    "should_continue = True\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "\n",
    "    data = batch[0]\n",
    "    targets = batch[1]\n",
    "    trace_names = batch[4]\n",
    "\n",
    "    hasEvent = False\n",
    "    hasNoise = False\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        trace_name = trace_names[i]\n",
    "        y = targets[i]\n",
    "        if y == 0:\n",
    "            actual_data = get_3c_wave_form(noise_hdf5_file, trace_name)\n",
    "            hasNoise = True\n",
    "            if not torch.equal(data[i], actual_data):\n",
    "                print(f'index={i}, data size={data.shape[0]}, batch_i={i}, y={y}, {trace_name} is not loaded properly')\n",
    "                should_continue = False\n",
    "                break\n",
    "        else:\n",
    "            actual_data = get_3c_wave_form(event_hdf5_file, trace_name)\n",
    "            hasEvent = True\n",
    "            if not torch.equal(data[i], actual_data):\n",
    "                print(f'index={i}, data size={data.shape[0]}, batch_i={i}, y={y}, {trace_name} is not loaded properly')\n",
    "                should_continue = False\n",
    "                break\n",
    "    \n",
    "    if not should_continue:\n",
    "        break\n",
    "    \n",
    "    print(f'index={i}, data size={data.shape[0]}, hasNoise={hasNoise}, hasEvent={hasEvent} everything is good!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32f497b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=255, data size=256, hasNoise=True, hasEvent=True everything is good!\n",
      "index=22, data size=23, hasNoise=True, hasEvent=True everything is good!\n"
     ]
    }
   ],
   "source": [
    "#Check data are loading properly\n",
    "\n",
    "#split_percentage=[train, validation, test]\n",
    "\n",
    "split_percentage=[1]\n",
    "split_index = 0\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, event_metadata_file, noise_hdf5_file, noise_metadata_file, \"binary\", padding_type=\"sample\", start_padding_value=40, end_padding_value=40, target_phase=False, phase_padding=100, remove_empty_phase=False, split_index=split_index, split_percentage=split_percentage)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=256, shuffle=True, num_workers=2\n",
    ")\n",
    "should_continue = True\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "\n",
    "    data = batch[0]\n",
    "    targets = batch[1]\n",
    "    trace_names = batch[4]\n",
    "\n",
    "    hasEvent = False\n",
    "    hasNoise = False\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        trace_name = trace_names[i]\n",
    "        y = targets[i]\n",
    "        if y == 0:\n",
    "            actual_data = get_3c_wave_form(noise_hdf5_file, trace_name)\n",
    "            hasNoise = True\n",
    "            if not torch.equal(data[i], actual_data):\n",
    "                print(f'index={i}, data size={data.shape[0]}, batch_i={i}, y={y}, {trace_name} is not loaded properly')\n",
    "                should_continue = False\n",
    "                break\n",
    "        else:\n",
    "            actual_data = get_3c_wave_form(event_hdf5_file, trace_name)\n",
    "            hasEvent = True\n",
    "            if not torch.equal(data[i], actual_data):\n",
    "                print(f'index={i}, data size={data.shape[0]}, batch_i={i}, y={y}, {trace_name} is not loaded properly')\n",
    "                should_continue = False\n",
    "                break\n",
    "    \n",
    "    if not should_continue:\n",
    "        break\n",
    "    \n",
    "    print(f'index={i}, data size={data.shape[0]}, hasNoise={hasNoise}, hasEvent={hasEvent} everything is good!')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6055f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_percentage=[1]\n",
    "split_index = 0\n",
    "\n",
    "dataset = InstanceDataset(event_hdf5_file, event_metadata_file, noise_hdf5_file, noise_metadata_file, \"box_trapezoidal\", padding_type=\"percentage\", start_padding_value=0, end_padding_value=0.4, target_phase=True, phase_padding=40, remove_empty_phase=True, split_index=split_index, split_percentage=split_percentage, norm_mode='max')\n",
    "\n",
    "datagenerator = DataGenerator(dataset, 4, True)\n",
    "\n",
    "batch = datagenerator[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
